{
 "metadata": {
  "name": "",
  "signature": "sha256:f555bc59e2eb0d9b6c01305e9224f537c9acfd1b5d4fe86ff962d9a0703e073e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import numpy as np\n",
      "import itertools\n",
      "from pyspark import SparkContext\n",
      "\n",
      "(USERNAME, ARTIST, TRACK, LOVED, FROM_PLAYLIST, TIMESTAMP, PLAYTIME, SESSION, DURATION) = range(0, 9)\n",
      "\n",
      "\n",
      "def parse_line(line, sep=\"##\"):\n",
      "    line_split = line.split(sep)\n",
      "    return line_split[USERNAME], line_split[ARTIST], line_split[TRACK], int(line_split[LOVED]), \\\n",
      "        int(line_split[FROM_PLAYLIST]), int(line_split[TIMESTAMP]),int(line_split[PLAYTIME]), int(line_split[SESSION]), int(line_split[DURATION])\n",
      "\n",
      "\n",
      "def parse_playlist_line(line):\n",
      "    line_split = line.split(\"\\t\")\n",
      "    user = line_split[0]\n",
      "    playlist = line_split[1].split(\"##\")\n",
      "    playlist_of_tuples = []\n",
      "    for i in range(0,len(playlist)-1):\n",
      "        playlist_of_tuples.append(tuple(playlist[i].split(\"/_/\")))\n",
      "    return user,playlist_of_tuples\n",
      "\n",
      "\n",
      "def compute_similarity(valueTuple):\n",
      "    playlists = valueTuple[0]\n",
      "    session_playlist = valueTuple[1][1]\n",
      "    maxJaccard = -1\n",
      "    for playlist in playlists:\n",
      "        currJaccard = compute_jaccard_index(set(session_playlist),set(playlist))\n",
      "        if currJaccard > maxJaccard:\n",
      "            maxJaccard = currJaccard\n",
      "    return maxJaccard\n",
      "\n",
      "def compute_similarity_levshtein(valueTuple):\n",
      "    playlists = valueTuple[0]\n",
      "    session_playlist = valueTuple[1][1]\n",
      "    maxJaccard = -1\n",
      "    bestPlaylist = None\n",
      "    for playlist in playlists:\n",
      "        currJaccard = compute_jaccard_index(set(session_playlist),set(playlist))\n",
      "        if currJaccard > maxJaccard:\n",
      "            maxJaccard = currJaccard\n",
      "            bestPlaylist = playlist\n",
      "    return levenshtein(session_playlist,bestPlaylist)\n",
      "\n",
      "def aggregateForUser(line):\n",
      "    return line[0][0],(line[0][1],line[1])\n",
      "\n",
      "def compute_jaccard_index(set_1,set_2):\n",
      "    n = len(set_1.intersection(set_2))\n",
      "    den = float(len(set_1) + len(set_2) - n)\n",
      "    if n == 0 or den == 0:\n",
      "        return 0\n",
      "    return n/float(len(set_1) + len(set_2) - n)\n",
      "\n",
      "def fun2OverOrderedSet(lista):\n",
      "    setres = set()\n",
      "    if len(lista) > 1:\n",
      "        for i in range(0,len(lista)-1):\n",
      "            if lista[i] != lista[i+1]:\n",
      "                setres.add((lista[i],lista[i+1]))\n",
      "    return setres\n",
      "\n",
      "def omega(sessions,playlists):\n",
      "    P = set()\n",
      "    for playlist in playlists:\n",
      "        for track in playlist:\n",
      "            P.add(track)\n",
      "    S = set()\n",
      "    for session in sessions:\n",
      "        for track in session:\n",
      "            S.add(track)\n",
      "    P2 = set()\n",
      "    for playlist in playlists:\n",
      "        pl = []\n",
      "        for track in playlist:\n",
      "            pl.append(track)\n",
      "        P2 = P2.union(fun2OverOrderedSet(pl))\n",
      "    S2 = set()\n",
      "    for session in sessions:\n",
      "        se = []\n",
      "        for track in session:\n",
      "            se.append(track)\n",
      "        S2 = S2.union(fun2OverOrderedSet(se))\n",
      "    inter = P.intersection(S)\n",
      "    cartprod = itertools.product(inter,repeat=2)\n",
      "    cart2 = set()\n",
      "    for e in cartprod:\n",
      "        cart2.add(e)\n",
      "    return compute_jaccard_index(P2.intersection(cart2),S2.intersection(cart2))\n",
      "\n",
      "\n",
      "def levenshtein(source, target):\n",
      "    if len(source) < len(target):\n",
      "        return levenshtein(target, source)\n",
      "\n",
      "    # So now we have len(source) >= len(target).\n",
      "    if len(target) == 0:\n",
      "        return len(source)\n",
      "\n",
      "    # We call tuple() to force strings to be used as sequences\n",
      "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
      "    source = np.array(tuple(source))\n",
      "    target = np.array(tuple(target))\n",
      "\n",
      "    # We use a dynamic programming algorithm, but with the\n",
      "    # added optimization that we only need the last two rows\n",
      "    # of the matrix.\n",
      "    previous_row = np.arange(target.size + 1)\n",
      "    for s in source:\n",
      "        # Insertion (target grows longer than source):\n",
      "        current_row = previous_row + 1\n",
      "\n",
      "        # Substitution or matching:\n",
      "        # Target and source items are aligned, and either\n",
      "        # are different (cost of 1), or are the same (cost of 0).\n",
      "        current_row[1:] = np.minimum(\n",
      "                current_row[1:],\n",
      "                np.add(previous_row[:-1], target != s))\n",
      "\n",
      "        # Deletion (target grows shorter than source):\n",
      "        current_row[1:] = np.minimum(\n",
      "                current_row[1:],\n",
      "                current_row[0:-1] + 1)\n",
      "\n",
      "        previous_row = current_row\n",
      "\n",
      "    return previous_row[-1]\n",
      "\n",
      "# def levenshtein(s1, s2):\n",
      "#     if len(s1) < len(s2):\n",
      "#         return levenshtein(s2, s1)\n",
      "#\n",
      "#     # len(s1) >= len(s2)\n",
      "#     if len(s2) == 0:\n",
      "#         return len(s1)\n",
      "#\n",
      "#     previous_row = range(len(s2) + 1)\n",
      "#     for i, c1 in enumerate(s1):\n",
      "#         current_row = [i + 1]\n",
      "#         for j, c2 in enumerate(s2):\n",
      "#             insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
      "#             deletions = current_row[j] + 1       # than s2\n",
      "#             substitutions = previous_row[j] + (c1 != c2)\n",
      "#             current_row.append(min(insertions, deletions, substitutions))\n",
      "#         previous_row = current_row\n",
      "#\n",
      "#     return previous_row[-1]\n",
      "\n",
      "def levenshtein(s, t):\n",
      "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
      "        if s == t: return 0\n",
      "        elif len(s) == 0: return len(t)\n",
      "        elif len(t) == 0: return len(s)\n",
      "        v0 = [None] * (len(t) + 1)\n",
      "        v1 = [None] * (len(t) + 1)\n",
      "        for i in xrange(len(v0)):\n",
      "            v0[i] = i\n",
      "        for i in xrange(len(s)):\n",
      "            v1[0] = i + 1\n",
      "            for j in xrange(len(t)):\n",
      "                cost = 0 if s[i] == t[j] else 1\n",
      "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
      "            for j in xrange(len(v0)):\n",
      "                v0[j] = v1[j]\n",
      "\n",
      "        return v1[len(t)]\n",
      "\n",
      "def computeOmega(valueTuple):\n",
      "    playlists = valueTuple[0];\n",
      "    agg_sessions = valueTuple[1];\n",
      "    sessions = [];\n",
      "    for agg_session in agg_sessions:\n",
      "        sessions.append(agg_session[1])\n",
      "    if len(playlists) == 0 or len(sessions) == 0:\n",
      "        return 0\n",
      "    return omega(sessions,playlists)\n",
      "\n",
      "def computeIntraSessionOmegaDictionaty(user_session_dict,key1,key2):\n",
      "    inter = user_session_dict[key1]['S1'].intersection(user_session_dict[key2]['S1'])\n",
      "    cartprod = itertools.product(inter,repeat=2)\n",
      "    cart2 = set()\n",
      "    for e in cartprod:\n",
      "        cart2.add(e)\n",
      "    return compute_jaccard_index(user_session_dict[key1]['S2'].intersection(cart2),user_session_dict[key2]['S2'].intersection(cart2))\n",
      "\n",
      "# def computeIntraSessionOmega(list_of_sessions):\n",
      "#     user_session_dict = {}\n",
      "#     for session in list_of_sessions:\n",
      "#         session_id = session[0]\n",
      "#         track_list = session[1]\n",
      "#         S1 = set()\n",
      "#         se = []\n",
      "#         for track in track_list:\n",
      "#             S1.add(track)\n",
      "#             se.append(track)\n",
      "#         user_session_dict[session_id] = {}\n",
      "#         user_session_dict[session_id]['S1'] = S1\n",
      "#         user_session_dict[session_id]['S2'] = fun2OverOrderedSet(se)\n",
      "#\n",
      "#\n",
      "#     omega_intra_sessions = {}\n",
      "#\n",
      "#     for key1 in user_session_dict:\n",
      "#         for key2 in user_session_dict:\n",
      "#             if key1 == key2:\n",
      "#                 continue\n",
      "#\n",
      "#             omega_intra_sessions.has_key((key1,key2))\n",
      "#             if not(omega_intra_sessions.has_key((key1,key2))) and not(omega_intra_sessions.has_key((key2,key1))):\n",
      "#                 omega_intra_sessions[(key1,key2)] = computeIntraSessionOmegaDictionaty(user_session_dict,key1,key2)\n",
      "#\n",
      "#     return omega_intra_sessions\n",
      "\n",
      "def computeIntraSessionJaccard(list_of_sessions):\n",
      "    user_session_dict = {}\n",
      "    count = 0\n",
      "    for session in list_of_sessions:\n",
      "        session_id = count\n",
      "        count = count + 1\n",
      "        track_list = session[1]\n",
      "        S1 = set()\n",
      "        for track in track_list:\n",
      "            S1.add(track)\n",
      "        user_session_dict[session_id] = {}\n",
      "        user_session_dict[session_id][\"track-set\"] = S1\n",
      "\n",
      "    jaccard_intra_sessions = {}\n",
      "    nsessions = count\n",
      "\n",
      "    for key1 in user_session_dict:\n",
      "        for key2 in user_session_dict:\n",
      "            if key1 == key2:\n",
      "                continue\n",
      "\n",
      "            jaccard_intra_sessions.has_key((key1,key2))\n",
      "            if not(jaccard_intra_sessions.has_key((key1,key2))) and not(jaccard_intra_sessions.has_key((key2,key1))):\n",
      "                jaccard_intra_sessions[(key1,key2)] = compute_jaccard_index(user_session_dict[key1][\"track-set\"],user_session_dict[key2][\"track-set\"])\n",
      "\n",
      "    return jaccard_intra_sessions,nsessions\n",
      "\n",
      "# def computeIntraSessionLevsthein(list_of_sessions):\n",
      "#     user_session_dict = {}\n",
      "#     for session in list_of_sessions:\n",
      "#         session_id = session[0]\n",
      "#         track_list = session[1]\n",
      "#         user_session_dict[session_id] = {}\n",
      "#         tlist = []\n",
      "#         for track in track_list:\n",
      "#             tlist.append(track)\n",
      "#         user_session_dict[session_id][\"track_list\"] = tlist\n",
      "#\n",
      "#     levstheins_intra_sessions = {}\n",
      "#\n",
      "#     for key1 in user_session_dict:\n",
      "#         for key2 in user_session_dict:\n",
      "#             if key1 == key2:\n",
      "#                 continue\n",
      "#\n",
      "#             levstheins_intra_sessions.has_key((key1,key2))\n",
      "#             if not(levstheins_intra_sessions.has_key((key1,key2))) and not(levstheins_intra_sessions.has_key((key2,key1))):\n",
      "#                 levstheins_intra_sessions[(key1,key2)] = levenshtein(user_session_dict[key1][\"track_list\"],user_session_dict[key2][\"track_list\"])\n",
      "#\n",
      "#     return levstheins_intra_sessions\n",
      "\n",
      "class UnionFind:\n",
      "    def __init__(self):\n",
      "        self.rank = {}\n",
      "        self.parent = {}\n",
      "\n",
      "    def find(self, element):\n",
      "        if element not in self.parent: # leader elements are not in `parent` dict\n",
      "            return element\n",
      "        if self.parent[element] == element:\n",
      "            return element\n",
      "        leader = self.find(self.parent[element]) # search recursively\n",
      "        self.parent[element] = leader # compress path by saving leader as parent\n",
      "        return leader\n",
      "\n",
      "    def union(self, leader1, leader2):\n",
      "        rank1 = self.rank.get(leader1,1)\n",
      "        rank2 = self.rank.get(leader2,1)\n",
      "\n",
      "        if rank1 > rank2: # union by rank\n",
      "            self.parent[leader2] = leader1\n",
      "        elif rank2 > rank1:\n",
      "            self.parent[leader1] = leader2\n",
      "        else: # ranks are equal\n",
      "            self.parent[leader2] = leader1 # favor leader1 arbitrarily\n",
      "            self.rank[leader1] = rank1+1 # increment rank\n",
      "\n",
      "def networks(friends, num_people):\n",
      "    # first process the \"friends\" list to build disjoint sets\n",
      "    network = UnionFind()\n",
      "\n",
      "    for a, b in friends:\n",
      "        network.union(network.find(a), network.find(b))\n",
      "\n",
      "    # now assemble the groups (indexed by an arbitrarily chosen leader)\n",
      "    groups = {}\n",
      "    for person in range(0,num_people):\n",
      "        g = groups.get(network.find(person), [])\n",
      "        g.append(person)\n",
      "        groups[network.find(person)] = g\n",
      "\n",
      "\n",
      "    groupList = []\n",
      "\n",
      "    # now print out the groups (you can call `set` on `g` if you want brackets)\n",
      "    for i, g in enumerate(groups.values()):\n",
      "        groupList.append(len(g))\n",
      "    if len(groupList) == 0:\n",
      "        return 1\n",
      "    np_groupList = np.array(groupList)\n",
      "\n",
      "    return np.mean(np_groupList)\n",
      "\n",
      "def clusterizeSessionsWithMetric(tuple,bins=10):\n",
      "    step = 1/float(bins)\n",
      "    res = []\n",
      "    intra_session_dictionary = tuple[0]\n",
      "    nsessions = tuple[1]\n",
      "    for i in range(0,bins):\n",
      "        threshold = i/float(bins)\n",
      "        filteredListByTh = []\n",
      "        for key in intra_session_dictionary:\n",
      "            # if key == \"nsessions\":\n",
      "            #     continue\n",
      "            if intra_session_dictionary[key]>=threshold:\n",
      "                filteredListByTh.append(key)\n",
      "        net = networks(filteredListByTh,nsessions)\n",
      "        # if i==0:\n",
      "        #     print str(net) + \" \" + str(nsessions) + \"list: \" + str(filteredListByTh)\n",
      "        res.append(net)\n",
      "    return np.array(res)\n",
      "\n",
      "def weightedAverageOfSessionSimilarityClusteredNonNormalized(session_length,similarities,bins):\n",
      "    #np_session_length = np.array(session_length)\n",
      "    cluster_size_to_be_plotted = np.zeros(bins)\n",
      "    total_sessions = 0\n",
      "    for i in range(len(session_length)):\n",
      "        ##numero medio di sessioni per cluster (normalizzato pesandolo per la lunghezza delle sessioni)\n",
      "        np.add(cluster_size_to_be_plotted,similarities[i]*session_length[i],cluster_size_to_be_plotted)\n",
      "        ##non ho ben capito cosa sia\n",
      "        #np.add(cluster_size_to_be_plotted,similarities[i],cluster_size_to_be_plotted)\n",
      "        total_sessions += session_length[i]\n",
      "\n",
      "    return np.dot(cluster_size_to_be_plotted,1/float(total_sessions))\n",
      "\n",
      "\n",
      "def weightedAverageOfSessionSimilarityClusteredNormalized(session_length,similarities,bins):\n",
      "    #np_session_length = np.array(session_length)\n",
      "    cluster_size_to_be_plotted = np.zeros(bins)\n",
      "    total_sessions = 0\n",
      "    for i in range(len(session_length)):\n",
      "        ##numero medio di sessioni per cluster (normalizzato pesandolo per la lunghezza delle sessioni)\n",
      "        #np.add(cluster_size_to_be_plotted,similarities[i]*session_length[i],cluster_size_to_be_plotted)\n",
      "        ##non ho ben capito cosa sia\n",
      "        np.add(cluster_size_to_be_plotted,similarities[i],cluster_size_to_be_plotted)\n",
      "        total_sessions += session_length[i]\n",
      "\n",
      "    return np.dot(cluster_size_to_be_plotted,1/float(total_sessions))\n",
      "\n",
      "def usersAverageOfSessionSimilarityClusteredNormalized(nusers,similarities,bins):\n",
      "    #np_session_length = np.array(session_length)\n",
      "    cluster_size_to_be_plotted = np.zeros(bins)\n",
      "\n",
      "    for i in range(len(similarities)):\n",
      "        ##numero medio di sessioni per cluster (normalizzato pesandolo per la lunghezza delle sessioni)\n",
      "        #np.add(cluster_size_to_be_plotted,similarities[i]*session_length[i],cluster_size_to_be_plotted)\n",
      "        ##non ho ben capito cosa sia\n",
      "        np.add(cluster_size_to_be_plotted,similarities[i],cluster_size_to_be_plotted)\n",
      "\n",
      "    return np.dot(cluster_size_to_be_plotted,1/float(nusers))\n",
      "\n",
      "def createMatlabPlot(x,y,file,openFileMode=\"w\"):\n",
      "    out = open(file,openFileMode)\n",
      "    xlist = \"\"\n",
      "    for i in x:\n",
      "        if xlist != \"\":\n",
      "            xlist = xlist + \",\"\n",
      "        xlist = xlist + str(i)\n",
      "    ylist = \"\"\n",
      "    for i in y:\n",
      "        if ylist != \"\":\n",
      "            ylist = ylist + \",\"\n",
      "        ylist = ylist + str(i)\n",
      "    out.write(\"plot([\" + xlist + \"],[\" + ylist + \"]);\\n\")\n",
      "    out.close()\n",
      "\n",
      "def createCumulativeMatlabPlotFromArrayOfTuples(arrayOfTuples,file,openFileMode=\"w\"):\n",
      "    out = open(file,openFileMode)\n",
      "    xlist = \"\"\n",
      "    ylist = \"\"\n",
      "    sumY = float(0)\n",
      "    for i in arrayOfTuples:\n",
      "        sumY = sumY + i[1]\n",
      "    for i in arrayOfTuples:\n",
      "        if xlist != \"\":\n",
      "            xlist = xlist + \",\"\n",
      "        if ylist != \"\":\n",
      "            ylist = ylist + \",\"\n",
      "        xlist = xlist + str(i[0])\n",
      "        ylist = ylist + str(i[1]/float(sumY))\n",
      "    \n",
      "    out.write(\"plot([\" + xlist + \"],[\" + ylist + \"]);\\n\")\n",
      "    out.close()\n",
      "\n",
      "def createMatlabPlotFromArrayOfTuples(arrayOfTuples,file,openFileMode=\"w\"):\n",
      "    out = open(file,openFileMode)\n",
      "    xlist = \"\"\n",
      "    ylist = \"\"\n",
      "    for i in arrayOfTuples:\n",
      "        if xlist != \"\":\n",
      "            xlist = xlist + \",\"\n",
      "        if ylist != \"\":\n",
      "            ylist = ylist + \",\"\n",
      "        xlist = xlist + str(i[0])\n",
      "        ylist = ylist + str(i[1])\n",
      "    \n",
      "    out.write(\"plot([\" + xlist + \"],[\" + ylist + \"]);\\n\")\n",
      "    out.close()\n",
      "    \n",
      "def averagePopularityPerUserAllSum(tuples,admittedTuplesFunc=lambda v1,v2: True):\n",
      "    num = 0\n",
      "    den = 0\n",
      "    count = 1\n",
      "    events = 0\n",
      "    for t in tuples:\n",
      "        if admittedTuplesFunc(*t) is False:\n",
      "            continue\n",
      "        num = num + t[0]\n",
      "        den = den + t[1]\n",
      "        count = count + 1\n",
      "        events = events + t[1]\n",
      "    print >> outfile, \"Users: \" + str(count)\n",
      "    print >> outfile, \"Support: \" + str(events)\n",
      "    return num/float(den)\n",
      "\n",
      "def averagePopularityPerUserMeanOfMean(tuples,admittedTuplesFunc=lambda v1,v2: True):\n",
      "    num = 0\n",
      "    den = 0\n",
      "    count = 1\n",
      "    events = 0\n",
      "    for t in tuples:\n",
      "        if admittedTuplesFunc(*t) is False:\n",
      "            continue\n",
      "        num = num + t[0]/float(t[1])\n",
      "        den = den + 1\n",
      "        count = count + 1\n",
      "        events = events + t[1]\n",
      "    print >> outfile, \"Users: \" + str(count)\n",
      "    print >> outfile, \"Support: \" + str(events)\n",
      "    return num/float(den)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def reconstrcutDataset(l):\n",
      "    outList = []\n",
      "    total = 0\n",
      "    for e in l:\n",
      "        total = total + e[0]\n",
      "    for e in l:\n",
      "        line = e[1]\n",
      "        outList.append((parse_line(line),total))\n",
      "    return outList\n",
      "\n",
      "def reconstructDataset2(l):\n",
      "    outList = []\n",
      "    for e in l:\n",
      "        outList.append(e)\n",
      "    return outList\n",
      "\n",
      "def computePlayCount(rdd):\n",
      "    return rdd.map(lambda line: ((line[USERNAME],line[ARTIST],line[TRACK]) , 1) ).reduceByKey(lambda l, r: l+r)\\\n",
      ".map(lambda x: (x[1],1) ).reduceByKey(lambda l, r: l+r).sortByKey(True).collect()\n",
      "\n",
      "dataset_path = \"/home/roberto/Desktop/statistiche_playlists/enriched/dataset_final.csv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "events_raw_rdd = sc.textFile(dataset_path)\n",
      "events_rdd = events_raw_rdd.map(lambda line: parse_line(line, \"##\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "tuttiNoSoglia = computePlayCount(events_rdd)\n",
      "tuttiGt5s = computePlayCount(events_rdd.filter(lambda line: line[PLAYTIME] > 5))\n",
      "tuttiLe5s = computePlayCount(events_rdd.filter(lambda line: line[PLAYTIME] <= 5))\n",
      "\n",
      "likeNoSoglia = computePlayCount(events_rdd.filter(lambda line: line[LOVED] == 1))\n",
      "likeGt5s = computePlayCount(events_rdd.filter(lambda line: (line[LOVED] == 1 and line[PLAYTIME] > 5)))\n",
      "likeLe5s = computePlayCount(events_rdd.filter(lambda line: (line[LOVED] == 1 and line[PLAYTIME] <= 5)))\n",
      "\n",
      "dislikeNoSoglia = computePlayCount(events_rdd.filter(lambda line: line[LOVED] == 0))\n",
      "dislikeGt5s = computePlayCount(events_rdd.filter(lambda line: (line[LOVED] == 0 and line[PLAYTIME] > 5)))\n",
      "dislikeLe5s = computePlayCount(events_rdd.filter(lambda line: (line[LOVED] == 0 and line[PLAYTIME] <= 5)))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#createMatlabPlotFromArrayOfTuples(tuttiNoSoglia,\"music/plotTest.txt\",\"w\")\n",
      "#createMatlabPlotFromArrayOfTuples(tuttiGt5s,\"music/plotTest.txt\",\"a\")\n",
      "#createMatlabPlotFromArrayOfTuples(tuttiLe5s,\"music/plotTest.txt\",\"a\")\n",
      "#createMatlabPlotFromArrayOfTuples(likeNoSoglia,\"music/plotTest.txt\",\"a\")\n",
      "#createMatlabPlotFromArrayOfTuples(likeGt5s,\"music/plotTest.txt\",\"a\")\n",
      "#createMatlabPlotFromArrayOfTuples(likeLe5s,\"music/plotTest.txt\",\"a\")\n",
      "\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiNoSoglia,\"music/plotTest.txt\",\"w\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiGt5s,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiLe5s,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeNoSoglia,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeGt5s,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeLe5s,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeNoSoglia,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeGt5s,\"music/plotTest.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeLe5s,\"music/plotTest.txt\",\"a\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "events_rdd_enriched_with_track_playcount = events_raw_rdd.map(lambda rawline:  ((rawline.split(\"##\")[ARTIST],rawline.split(\"##\")[TRACK]) , (1,rawline)) ).groupByKey().flatMap(lambda x: reconstrcutDataset(x[1]))\n",
      "\n",
      "minNumTrackPlayCount = 100\n",
      "\n",
      "filtered = events_rdd_enriched_with_track_playcount.filter(lambda x: x[1] >= minNumTrackPlayCount).map(lambda x: ( x[0][USERNAME],x[0] )).groupByKey().filter(lambda x: len(x[1]) >= minNumTrackPlayCount).flatMap(lambda x: reconstructDataset2(x[1]) )\n",
      "support = filtered.count()\n",
      "\n",
      "print support\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11033723\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tuttiNoSoglia100 = computePlayCount(filtered)\n",
      "tuttiGt5s100 = computePlayCount(filtered.filter(lambda line: line[PLAYTIME] > 5))\n",
      "tuttiLe5s100 = computePlayCount(filtered.filter(lambda line: line[PLAYTIME] <= 5))\n",
      "\n",
      "likeNoSoglia100 = computePlayCount(filtered.filter(lambda line: line[LOVED] == 1))\n",
      "likeGt5s100 = computePlayCount(filtered.filter(lambda line: (line[LOVED] == 1 and line[PLAYTIME] > 5)))\n",
      "likeLe5s100 = computePlayCount(filtered.filter(lambda line: (line[LOVED] == 1 and line[PLAYTIME] <= 5)))\n",
      "\n",
      "dislikeNoSoglia100 = computePlayCount(filtered.filter(lambda line: line[LOVED] == 0))\n",
      "dislikeGt5s100 = computePlayCount(filtered.filter(lambda line: (line[LOVED] == 0 and line[PLAYTIME] > 5)))\n",
      "dislikeLe5s100 = computePlayCount(filtered.filter(lambda line: (line[LOVED] == 0 and line[PLAYTIME] <= 5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiNoSoglia100,\"music/plotTest100.txt\",\"w\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiGt5s100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(tuttiLe5s100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeNoSoglia100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeGt5s100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(likeLe5s100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeNoSoglia100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeGt5s100,\"music/plotTest100.txt\",\"a\")\n",
      "createCumulativeMatlabPlotFromArrayOfTuples(dislikeLe5s100,\"music/plotTest100.txt\",\"a\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "totEvents = events_rdd.count()\n",
      "percentageSkippedAll = events_rdd.filter(lambda line: line[PLAYTIME] <= 5).count()/float(totEvents)\n",
      "\n",
      "totLikedEvents = events_rdd.filter(lambda line: line[LOVED] == 1).count()\n",
      "percentageSkippedLike = events_rdd.filter(lambda line: (line[LOVED] == 1 and line[PLAYTIME] <= 5)).count()/float(totLikedEvents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print percentageSkippedAll\n",
      "print percentageSkippedLike\n",
      "print totEvents\n",
      "print totLikedEvents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.136878780567\n",
        "0.155629062467\n",
        "31351945\n",
        "4106341\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "variables": {}
     },
     "source": [
      "<h1>Analisi Jaccard</h1>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped_user_sessions = events_rdd.map(lambda line: ((line[USERNAME],line[SESSION]) , (line[ARTIST],line[TRACK]) )).groupByKey()\n",
      "gusPerUser = grouped_user_sessions.map(lambda line: aggregateForUser(line))\n",
      "gusPerUserAggregated = gusPerUser.groupByKey()\n",
      "nusers = gusPerUserAggregated.map(lambda x: x[0]).count()\n",
      "session_length = gusPerUserAggregated.map(lambda x: len(x[1])).collect()\n",
      "intraSessionJaccards = gusPerUserAggregated.map(lambda x: clusterizeSessionsWithMetric(computeIntraSessionJaccard(x[1]),bins)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wnn = weightedAverageOfSessionSimilarityClusteredNonNormalized(session_length,intraSessionJaccards,bins)\n",
      "wn = weightedAverageOfSessionSimilarityClusteredNormalized(session_length,intraSessionJaccards,bins)\n",
      "unn = usersAverageOfSessionSimilarityClusteredNormalized(nusers,intraSessionJaccards,bins)\n",
      "\n",
      "createMatlabPlot(np.arange(0,1,0.1),wnn,\"music/jaccard.m\",\"w\")\n",
      "createMatlabPlot(np.arange(0,1,0.1),wn,\"music/jaccard.m\",\"a\")\n",
      "createMatlabPlot(np.arange(0,1,0.1),unn,\"music/jaccard.m\",\"a\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Jaccards\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped_user_sessionsF = filtered.map(lambda line: ((line[USERNAME],line[SESSION]) , (line[ARTIST],line[TRACK]) )).groupByKey()\n",
      "gusPerUserF = grouped_user_sessionsF.map(lambda line: aggregateForUser(line))\n",
      "gusPerUserAggregatedF = gusPerUserF.groupByKey()\n",
      "nusersF = gusPerUserAggregatedF.map(lambda x: x[0]).count()\n",
      "session_lengthF = gusPerUserAggregatedF.map(lambda x: len(x[1])).collect()\n",
      "intraSessionJaccardsF = gusPerUserAggregatedF.map(lambda x: clusterizeSessionsWithMetric(computeIntraSessionJaccard(x[1]),bins)).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wnnF = weightedAverageOfSessionSimilarityClusteredNonNormalized(session_lengthF,intraSessionJaccardsF,bins)\n",
      "wnF = weightedAverageOfSessionSimilarityClusteredNormalized(session_lengthF,intraSessionJaccardsF,bins)\n",
      "unnF = usersAverageOfSessionSimilarityClusteredNormalized(nusersF,intraSessionJaccardsF,bins)\n",
      "\n",
      "createMatlabPlot(np.arange(0,1,0.1),wnnF,\"music/jaccardFiltered.m\",\"w\")\n",
      "createMatlabPlot(np.arange(0,1,0.1),wnF,\"music/jaccardFiltered.m\",\"a\")\n",
      "createMatlabPlot(np.arange(0,1,0.1),unnF,\"music/jaccardFiltered.m\",\"a\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Jaccards\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}