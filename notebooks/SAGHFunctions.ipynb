{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile('../spark-scripts/split.py')\n",
    "execfile('../spark-scripts/utils.py')\n",
    "execfile('../spark-scripts/eval.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "conf = {}\n",
    "\n",
    "conf['split'] = {}\n",
    "conf['split']['reclistSize'] = 100\n",
    "conf['split']['callParams'] = {}\n",
    "conf['split']['excludeAlreadyListenedTest'] = True\n",
    "conf['split']['name'] = 'giroCompletoTestMultipleConfs_excludeTrue'\n",
    "conf['split']['minEventsPerUser'] = 5\n",
    "conf['split']['inputData'] = 's3n://contentwise-research-poli/30musicdataset/newFormat/relations/sessions.idomaar'\n",
    "conf['split']['bucketName'] = 'contentwise-research-poli'\n",
    "conf['split']['percUsTr'] = 0.05\n",
    "conf['split']['ts'] = int(0.75 * (1421745857 - 1390209860) + 1390209860) - 10000\n",
    "conf['split']['minEventPerSession'] = 5\n",
    "conf['split']['onlineTrainingLength'] = 5\n",
    "conf['split']['GTlength'] = 5\n",
    "conf['split']['minEventPerSessionTraining'] = 10\n",
    "conf['split']['minEventPerSessionTest'] = 11\n",
    "conf['split']['mode'] = 'session'\n",
    "conf['split']['forceSplitCreation'] = False\n",
    "\n",
    "conf['evaluation'] = {}\n",
    "conf['evaluation']['metric'] = {}\n",
    "conf['evaluation']['metric']['type'] = 'recall'\n",
    "conf['evaluation']['metric']['prop'] = {}\n",
    "conf['evaluation']['metric']['prop']['N'] = [1,2,5,10,15,20,25,50,100]\n",
    "conf['evaluation']['name'] = 'recall@N'\n",
    "\n",
    "conf['general'] = {}\n",
    "conf['general']['clientname'] = 'split'\n",
    "conf['general']['bucketName'] = 'contentwise-research-poli'\n",
    "conf['general']['tracksPath'] = '30Mdataset/entities/tracks.idomaar.gz'\n",
    "\n",
    "conf['algo'] = {}\n",
    "conf['algo']['name'] = 'SAGH'\n",
    "conf['algo']['props'] = {}\n",
    "# ***** EXAMPLE OF CONFIGURATION *****#\n",
    "conf['algo']['props']['numGH'] = 10\n",
    "conf['algo']['props']['skipTh'] = 0\n",
    "# ****** END EXAMPLE ****************#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basePath = path.join('s3n://', conf['general']['bucketName'])\n",
    "trackPath = path.join(basePath, '30Mdataset/entities/tracks.idomaar.gz')\n",
    "trackRDD = sc.textFile(trackPath).cache()\n",
    "train,test = loadDataset(conf) #loads training and test users events, then generates the train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def readJson(x,field='artists',pos=4):\n",
    "    ##if field == \"\": return json.loads(x[pos])\n",
    "    return json.loads(x[pos])[field]\n",
    "\n",
    "## artistLookupRDD = (trackId, artistID)\n",
    "tabSplit = lambda x: x.split(\"\\t\")\n",
    "ext = lambda x: (int(x[1]), int(readJson(x)[0]['id']))\n",
    "artistLookupRDD = trackRDD.map(tabSplit).map(ext).distinct().persist()\n",
    "artistLookupRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## (trackId,sessionId)\n",
    "ext = lambda x: ([(k['id'],k['playratio'], x['id']) for k in x['linkedinfo']['objects']])\n",
    "th = conf['algo']['props']['skipTh']\n",
    "batchTrainingRDD = train.flatMap(lambda x: ext(json.loads(x))).filter(lambda x: x[1] > th)\\\n",
    "                .map(lambda x: (int(x[0]), int(x[2]))).persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchTrainingRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## sessionId, (trackId, artistId)\n",
    "joinedRDD = artistLookupRDD.join(batchTrainingRDD).map(lambda x: (x[1][1],(x[0],x[1][0]))).persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinedRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greatist Hits of each artist (i.e., the top n most popular tracks for each artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## top popular track per artist\n",
    "## trackId_artistId\n",
    "from operator import add\n",
    "parser = lambda x: (x[1], 1)\n",
    "prep = lambda x: (x[0][1], [(x[0][0], x[1])])\n",
    "\n",
    "def sorter(x,n):\n",
    "    if type(x[1]) != list: \n",
    "        result = list()\n",
    "        result.append(x[1])\n",
    "        return result\n",
    "    a = x[1]\n",
    "    if len(a) <= n: n=len(a)\n",
    "    return (x[0],sorted(a,key=lambda k: -k[1])[0:n])\n",
    "\n",
    "numGH = conf['algo']['props']['numGH']\n",
    "sort = lambda x: sorter(x, numGH)\n",
    "uni = lambda x: x[1] > 1\n",
    "\n",
    "artistGreatistHitsRDD = joinedRDD.map(parser).reduceByKey(add).filter(uni).map(prep).reduceByKey(add).map(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artistGreatistHitsRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation:  parsing the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext2 = lambda x: [(int(x['id']), int(l['id']), l['playratio']) for l in x['linkedinfo']['objects']]\n",
    "recReqRDD =  test.flatMap(lambda x: ext2(json.loads(x)))\\\n",
    "            .filter(lambda x: x[2] > th).map(lambda x: (x[1], x[0])).join(artistLookupRDD)\\\n",
    "            .map(lambda x: ((x[1][1], x[1][0]), [(x[0])])).reduceByKey(add)\\\n",
    "            .map(lambda x: (x[0][0], (x[0][1], x[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recReqRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinedRec = recReqRDD.join(artistGreatistHitsRDD).persist()\n",
    "joinedRec.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validator(x):\n",
    "    recID = x[1][0][0]\n",
    "    trackList = x[1][0][1]\n",
    "    recList = x[1][1]\n",
    "    rec = [l for l in recList if l[0] not in trackList]\n",
    "    return (recID,rec)\n",
    "\n",
    "val = lambda x: validator(x)\n",
    "\n",
    "def sorter(x,length):\n",
    "    a = x[1]\n",
    "    if len(a) > length: length = len(a) \n",
    "    return sorted(a,key=lambda k: -k[1])[0:length]\n",
    "\n",
    "recLength = conf['split']['reclistSize']\n",
    "s = lambda x: (x[0], sorter(x, recLength))\n",
    "\n",
    "rec = joinedRec.map(val).reduceByKey(add).map(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rec.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate recommendations in the right format, then test\n",
    "def addResponse(reqJson, respJson):\n",
    "    req = json.loads(reqJson)\n",
    "    req['linkedinfo'].update({'response': respJson})\n",
    "    return json.dumps(req)\n",
    "\n",
    "def formatResponse(rank_list, response_size=100):\n",
    "    return [{'type': 'track', 'id': id, 'rank': rank} for rank, (id, _) in enumerate(rank_list[:response_size])]\n",
    "\n",
    "responses = test.map(lambda x: (json.loads(x)['id'], x))\\\n",
    "    .join(rec)\\\n",
    "    .map(lambda x: addResponse(x[1][0], formatResponse(x[1][1], json.loads(x[1][0])['properties']['reclistSize'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saveRecommendations(conf, responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeMetrics(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
