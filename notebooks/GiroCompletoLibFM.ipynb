{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all the auxiliary functions\n",
    "execfile('../spark-scripts/eval.py')\n",
    "execfile('../spark-scripts/split.py')\n",
    "execfile('../spark-scripts/utils.py')\n",
    "execfile('../spark-scripts/FMAlgoFunctions.py')\n",
    "execfile('../spark-scripts/FMAlgoMain.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "conf = {}\n",
    "\n",
    "conf['split'] = {}\n",
    "conf['split']['reclistSize'] = 100\n",
    "conf['split']['callParams'] = {}\n",
    "conf['split']['excludeAlreadyListenedTest'] = True\n",
    "conf['split']['name'] = '0_1SPLIT_1413851857_sessionsession_1413851857'\n",
    "conf['split']['minEventsPerUser'] = 5\n",
    "conf['split']['inputData'] = 's3n://contentwise-research-poli/0_1SPLIT_1413851857_sessionsession_1413851857'\n",
    "#conf['split']['inputData'] = 's3n://contentwise-research-poli/30musicdataset/newFormat/relations/sessions.idomaar'\n",
    "conf['split']['bucketName'] = 'contentwise-research-poli'\n",
    "conf['split']['percUsTr'] = 0.05\n",
    "conf['split']['ts'] = int(0.75 * (1421745857 - 1390209860) + 1390209860) - 10000\n",
    "conf['split']['minEventPerSession'] = 5\n",
    "conf['split']['onlineTrainingLength'] = 5\n",
    "conf['split']['GTlength'] = 5\n",
    "conf['split']['minEventPerSessionTraining'] = 10\n",
    "conf['split']['minEventPerSessionTest'] = 11\n",
    "conf['split']['mode'] = 'session'\n",
    "conf['split']['forceSplitCreation'] = False\n",
    "\n",
    "conf['evaluation'] = {}\n",
    "conf['evaluation']['metric'] = {}\n",
    "conf['evaluation']['metric']['type'] = 'recall'\n",
    "conf['evaluation']['metric']['prop'] = {}\n",
    "conf['evaluation']['metric']['prop']['N'] = [1,2,5,10,15,20,25,50,100]\n",
    "conf['evaluation']['name'] = 'recall@N'\n",
    "\n",
    "conf['general'] = {}\n",
    "conf['general']['clientname'] = \"split2.split\"\n",
    "conf['general']['bucketName'] = 'contentwise-research-poli'\n",
    "conf['general']['tmpDir'] = \"/tmp\"\n",
    "\n",
    "conf['algo'] = {}\n",
    "conf['algo']['name'] = 'LibFM_fixed'\n",
    "conf['algo']['props'] = {}\n",
    "# ***** EXAMPLE OF CONFIGURATION *****#\n",
    "conf['algo']['props']['collaborativity'] = 'knn' #individual, (all), knn\n",
    "conf['algo']['props']['neighborhoodSize'] = 2 #neighborhood size for the knn collaborativity (NOTE: it includes the user itself! set to 2 for the closest neighbor)\n",
    "conf['algo']['props']['duplicatePolicy'] = 'unique_max' #none, unique_max, unique_min\n",
    "conf['algo']['props']['historyAggrPolicy'] = 'count' #count, avg, max, min, [exp_decay and others to be implemented]\n",
    "conf['algo']['props']['trainGenPolicy'] = 'leaveoneout' #leaveoneout, sequential\n",
    "conf['algo']['props']['latentSize'] = 2\n",
    "conf['algo']['props']['libFMbin'] = \"/home/massimo/recsys/libfm/bin/./libFM\"\n",
    "conf['algo']['props']['libFMopt'] = \"-task c -dim '1,1,25' -iter 50\" \n",
    "conf['algo']['props']['shuffleTraining'] = True\n",
    "conf['algo']['props']['maxRequestsPerUser'] = 10\n",
    "# ****** END EXAMPLE ****************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "historyAggrPolicies = ['count', 'avg']\n",
    "trainGenPolicies = ['leaveoneout', 'sequential']\n",
    "#collaborativityTypes = ['individual', 'knn', 'all']\n",
    "collaborativityTypes = ['individual', 'knn']\n",
    "neighSizes = [2**i for i in xrange(1,7)]\n",
    "latentSizes = [2**i for i in xrange(2,7)]\n",
    "\n",
    "coll_neigh = [(c, 1) for c in collaborativityTypes if c is not 'knn']\n",
    "if 'knn' in collaborativityTypes:\n",
    "    coll_neigh += [('knn', s) for s in neighSizes]\n",
    "\n",
    "#for exclude in [True,False]:\n",
    "#for exclude in [True]:\n",
    "#    conf['split']['name'] = 'giroCompletoTestMultipleConfs_exclude%s' % exclude\n",
    "#    splitter(conf)\n",
    "train, test = loadDataset(conf)\n",
    "\n",
    "for historyAggrPolicy in historyAggrPolicies:\n",
    "    conf['algo']['props']['historyAggrPolicy'] = historyAggrPolicy\n",
    "    trainSessionHistoryAggr, testRequestsHistoryAggr = sessionAggregation(train, test, conf)\n",
    "    \n",
    "    for trainGenPolicy in trainGenPolicies:\n",
    "        print \n",
    "        conf['algo']['props']['trainGenPolicy'] = trainGenPolicy\n",
    "        training = generateTraining(trainSessionHistoryAggr, conf)\n",
    "        \n",
    "        for coll, neigh_size in coll_neigh:\n",
    "            conf['algo']['props']['collaborativity'] = coll\n",
    "            conf['algo']['props']['neighborhoodSize'] = neigh_size\n",
    "            trainSessionsPerUser, testRequestsPerUser = filterTrainSessionsPerUser(training, trainSessionHistoryAggr, testRequestsHistoryAggr, conf)\n",
    "            \n",
    "            for latentSize in latentSizes:\n",
    "                conf['algo']['props']['latentSize'] = latentSize\n",
    "                conf['algo']['props']['libFMopt'] = \"-task c -dim '1,1,%d' -iter 50\" % latentSize\n",
    "                recomm = generateRecommendationsLibFM(trainSessionsPerUser, testRequestsPerUser, test, conf)\n",
    "                try:\n",
    "                    saveRecommendations(conf, recomm, overwrite=True)\n",
    "                    computeMetrics(conf)\n",
    "                except Exception as e:\n",
    "                    print e\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a54192a095b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'props'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'libFMopt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-task c -method als -dim '1,1,%d' -iter 50\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlatentSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrecomm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateRecommendationsLibFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSessionsPerUser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestRequestsPerUser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0msaveRecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecomm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mcomputeMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/massimo/workspace/spark-scripts/music/scripts/ToBeUploaded/utils.py\u001b[0m in \u001b[0;36msaveRecommendations\u001b[0;34m(conf, recJsonRdd, overwrite)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# save recommendations to S3 storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3n://'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'general'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bucketName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recommendations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mrecJsonRdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Recommendations successfully written to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-1.3.0-bin-hadoop2.4/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[0;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0mkeyed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[0;31m# Pair functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m    538\u001b[0m                 self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    428\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split2.split/0_1SPLIT_1413851857_sessionsession_1413851857/Rec/LibFM_fixed_leaveoneout#unique_max#4#avg#1#individual successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "# DEBUG SCRIPT\n",
    "\n",
    "historyAggrPolicies = ['avg']\n",
    "trainGenPolicies = ['leaveoneout']\n",
    "#collaborativityTypes = ['individual', 'knn', 'all']\n",
    "collaborativityTypes = ['individual']\n",
    "neighSizes = [4]\n",
    "latentSizes = [4]\n",
    "\n",
    "coll_neigh = [(c, 1) for c in collaborativityTypes if c is not 'knn']\n",
    "if 'knn' in collaborativityTypes:\n",
    "    coll_neigh += [('knn', s) for s in neighSizes]\n",
    "\n",
    "\n",
    "#for exclude in [True]:\n",
    "#    conf['split']['name'] = 'giroCompletoTestMultipleConfs_exclude' + str(exclude)\n",
    "#    splitter(conf)\n",
    "train, test = loadDataset(conf)\n",
    "\n",
    "for historyAggrPolicy in historyAggrPolicies:\n",
    "    conf['algo']['props']['historyAggrPolicy'] = historyAggrPolicy\n",
    "    trainSessionHistoryAggr, testRequestsHistoryAggr = sessionAggregation(train, test, conf)\n",
    "    \n",
    "    for trainGenPolicy in trainGenPolicies:\n",
    "        conf['algo']['props']['trainGenPolicy'] = trainGenPolicy\n",
    "        training = generateTraining(trainSessionHistoryAggr, conf)\n",
    "        \n",
    "        for coll, neigh_size in coll_neigh:\n",
    "            conf['algo']['props']['collaborativity'] = coll\n",
    "            conf['algo']['props']['neighborhoodSize'] = neigh_size\n",
    "            trainSessionsPerUser, testRequestsPerUser = filterTrainSessionsPerUser(training, trainSessionHistoryAggr, testRequestsHistoryAggr, conf)\n",
    "            \n",
    "            for latentSize in latentSizes:\n",
    "                conf['algo']['props']['latentSize'] = latentSize\n",
    "                conf['algo']['props']['libFMopt'] = \"-task c -method als -dim '1,1,%d' -iter 50\" % latentSize\n",
    "                recomm = generateRecommendationsLibFM(trainSessionsPerUser, testRequestsPerUser, test, conf)\n",
    "                saveRecommendations(conf, recomm, overwrite=True)\n",
    "                computeMetrics(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
